{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(container_path, description=None, categories=None,\n",
    "               load_content=True, shuffle=True, target_size=None, gray=True, flatten=True, random_state=0):\n",
    "    from sklearn.utils import Bunch, check_random_state\n",
    "    import cv2\n",
    "    from os import environ, listdir, makedirs\n",
    "    from os.path import dirname, exists, expanduser, isdir, join, splitext\n",
    "    import numpy as np\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    description : string or unicode, optional (default=None)\n",
    "        A paragraph describing the characteristic of the dataset: its source,\n",
    "        reference, etc.\n",
    "    categories : A collection of strings or None, optional (default=None)\n",
    "        If None (default), load all the categories. If not None, list of\n",
    "        category names to load (other categories ignored).\n",
    "    load_content : boolean, optional (default=True)\n",
    "        Whether to load or not the content of the different files. If true a\n",
    "        'data' attribute containing the text information is present in the data\n",
    "        structure returned. If not, a filenames attribute gives the path to the\n",
    "        files.\n",
    "    shuffle : bool, optional (default=True)\n",
    "        Whether or not to shuffle the data: might be important for models that\n",
    "        make the assumption that the samples are independent and identically\n",
    "        distributed (i.i.d.), such as stochastic gradient descent.\n",
    "    encoding : string or None (default is None)\n",
    "        If None, do not try to decode the content of the files (e.g. for images\n",
    "        or other non-text content). If not None, encoding to use to decode text\n",
    "        files to Unicode if load_content is True.\n",
    "    decode_error : {'strict', 'ignore', 'replace'}, optional\n",
    "        Instruction on what to do if a byte sequence is given to analyze that\n",
    "        contains characters not of the given `encoding`. Passed as keyword\n",
    "        argument 'errors' to bytes.decode.\n",
    "    random_state : int, RandomState instance or None (default=0)\n",
    "        Determines random number generation for dataset shuffling. Pass an int\n",
    "        for reproducible output across multiple function calls.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "    Returns\n",
    "    -------\n",
    "    data : Bunch\n",
    "        Dictionary-like object, the interesting attributes are: either\n",
    "        data, the raw text data to learn, or 'filenames', the files\n",
    "        holding it, 'target', the classification labels (integer index),\n",
    "        'target_names', the meaning of the labels, and 'DESCR', the full\n",
    "        description of the dataset.\n",
    "    \"\"\"\n",
    "    target = []\n",
    "    target_names = []\n",
    "    filenames = []\n",
    "\n",
    "    folders = [f for f in sorted(listdir(container_path))\n",
    "               if isdir(join(container_path, f))]\n",
    "\n",
    "    if categories is not None:\n",
    "        folders = [f for f in folders if f in categories]\n",
    "\n",
    "    for label, folder in enumerate(folders):\n",
    "        target_names.append(folder)\n",
    "        folder_path = join(container_path, folder)\n",
    "        documents = [join(folder_path, d)\n",
    "                     for d in sorted(listdir(folder_path))]\n",
    "        target.extend(len(documents) * [label])\n",
    "        filenames.extend(documents)\n",
    "\n",
    "    # convert to array for fancy indexing\n",
    "    filenames = np.array(filenames)\n",
    "    target = np.array(target)\n",
    "\n",
    "    if shuffle:\n",
    "        random_state = check_random_state(random_state)\n",
    "        indices = np.arange(filenames.shape[0])\n",
    "        random_state.shuffle(indices)\n",
    "        filenames = filenames[indices]\n",
    "        target = target[indices]\n",
    "\n",
    "    if load_content:\n",
    "        data = []\n",
    "        for filename in filenames:\n",
    "            img = cv2.imread(filename)\n",
    "            if target_size:\n",
    "                img = cv2.resize(img, target_size)\n",
    "            if gray:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
    "            if flatten:\n",
    "                img = img.flatten()\n",
    "            data.append(img)\n",
    "        data = np.array(data)\n",
    "        return Bunch(data=data,\n",
    "                     filenames=filenames,\n",
    "                     target_names=target_names,\n",
    "                     target=target,\n",
    "                     DESCR=description)\n",
    "\n",
    "    return Bunch(filenames=filenames,\n",
    "                 target_names=target_names,\n",
    "                 target=target,\n",
    "                 DESCR=description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_images('data/data_new', target_size=(64, 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
